#This script runs the re-trained Inception model to classify a single or a batch of images

import subprocess
from PIL import Image
import matplotlib.pyplot as plt
import pathlib
from datetime import datetime
import time
import tensorflow as tf, sys
import numpy as np
import random

#import os
#os.environ["CUDA_VISIBLE_DEVICES"] = "0"

def plot_images(image, Caption1):

    #plt.close()
    
    plt.rcParams['text.usetex'] = False
    plt.rcParams['font.size'] = 10
    plt.rcParams['font.family'] = 'Arial'
    
    fig, ax = plt.subplots(1, 1)
    ax.imshow(image)
    xlabel = Caption1
    ax.set_xlabel(xlabel)
    ax.set_xticks([])
    ax.set_yticks([])
    plt.show()
    
def classify_image(image_path, model_path, labels_path):
    # Read in the image_data
    time_start = time.monotonic()
    config = tf.compat.v1.ConfigProto()
    config.gpu_options.allow_growth=True
    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(
    allow_soft_placement=True,
    log_device_placement=True))

    image_data = tf.io.gfile.GFile(image_path, 'rb').read()

    # Loads label file, strips off carriage return
    with tf.io.gfile.GFile(labels_path, 'r') as f:
        label_lines = [line.strip() for line 
                        in f.readlines()]
    #label_lines = [line.rstrip() for line 
    #                   in tf.io.gfile.GFile(labels_path)]

    # Unpersists graph from file
    with tf.io.gfile.GFile(model_path, 'rb') as f:
        graph_def = tf.compat.v1.GraphDef()
        graph_def.ParseFromString(f.read())
        _ = tf.import_graph_def(graph_def, name='')

    with sess.as_default() as sess:
        # Feed the image_data as input to the graph and get first prediction
        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')
        
        predictions = sess.run(softmax_tensor, \
                 {'DecodeJpeg/contents:0': image_data})
        # Sort to show labels of first prediction in order of confidence
        
        pr=np.argmax(predictions)
        pr_P=predictions[0][pr]
        print('Predicted class index:', pr)
        print('Predicted class probability:', pr_P)
        
        top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]
        print(top_k, label_lines)
        print(predictions)
        output_label = ""
        
        
        
        for node_id in top_k:
            human_string = label_lines[node_id]
            score = predictions[0][node_id]
            output_label = output_label + human_string + "({0:.4f})".format(score) + " "
            print('%s (score = %.5f)' % (human_string, score))
        print(output_label)
        output_label = output_label + " Runtime: " + "{0:.2f}".format(time.monotonic()-time_start) + "s"
    
    image = Image.open(image_path)
    plot_images(image,output_label)
    sess.close()
	
# change this as you see fit; model_dir is the folder containing the retrained_graph.pb and retrained_labels.txt files generated by retrain.py; image_dir contains subfolders that contain the images to be assessed
mydirpath = 'C:/seeun/Git/capstone/FaceShapeClassification/inception-face-shape-classifier'
model_dir = mydirpath + "/result"
imagedir = mydirpath + "/input"

model_path = model_dir + "/retrained_graph.pb"
labels_path = model_dir + "/retrained_labels.txt"
batch_run = 0

if (batch_run == 1):
	# Read in the image_data
	print("Initializing...")
	time_start = time.monotonic()
	config = tf.compat.v1.ConfigProto()
	config.gpu_options.allow_growth=True
	sess = tf.compat.v1.Session(config=config)

	# Loads label file, strips off carriage return
	label_lines = [line.rstrip() for line 
						in tf.io.gfile.GFile(labels_path)]

	# Unpersists graph from file
	# 수정
	with tf.io.gfile.GFile(model_path, 'rb') as f:
		graph_def = tf.compat.v1.GraphDef()
		graph_def.ParseFromString(f.read())
		_ = tf.import_graph_def(graph_def, name='')

	with sess.as_default() as sess:
	
		# Feed the image_data as input to the graph and get first prediction
		softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')
		sub_dir = [q for q in pathlib.Path(imagedir).iterdir() if q.is_dir()]
	
		result_summary = []
		labels = ['heart', 'oblong', 'oval', 'round', 'square']
		for j in range(len(sub_dir)):
			print("j = ",j, " ", sub_dir[j])
			images_dir = [p for p in pathlib.Path(sub_dir[j]).iterdir() if p.is_file()]
			for i in range(len(images_dir)):
				
				image_path = str(images_dir[i])
				# 수정
				image_data = tf.io.gfile.GFile(image_path, 'rb').read()
				predictions = sess.run(softmax_tensor, \
						{'DecodeJpeg/contents:0': image_data})
	
				# Sort to show labels of first prediction in order of confidence
				top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]
	
				txt = str(images_dir[i]) + " " + label_lines[top_k[0]] + " " + str(top_k[0])+ " " + str(top_k[1])+ " " + str(top_k[2])+ " " + str(top_k[3])+ " " + str(top_k[4]) + "\n"
				print(image_path, " ", txt)
			
				output_label = ""
			
				for node_id in top_k:
					human_string = label_lines[node_id]
					score = predictions[0][node_id]
					output_label = output_label + human_string + "({0:.4f})".format(score) + " "
				output_label = output_label + " Runtime: " + "{0:.2f}".format(time.monotonic()-time_start) + "s"
	
				image = Image.open(image_path)
				plot_images(image,output_label)
		sess.close()


if (batch_run ==0):
	images_dir = [p for p in pathlib.Path(imagedir).iterdir() if p.is_file()]
	#print(dir(images_dir)) #print(images_dir.__sizeof__()) #print(type(images_dir)) #print(len(images_dir))

	for i in range(len(images_dir)):
		#print(images_dir[i], type(images_dir[i])) #print(str(images[i])) #Image.open(images_dir[i]).show()
		print("Processing ", images_dir[i], "...", end=' ', sep='') 
		classify_image(str(images_dir[i]), model_path, labels_path)
		plt.show()